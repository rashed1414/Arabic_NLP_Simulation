{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "705a0501",
   "metadata": {},
   "source": [
    "# Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54df4a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules Imported !! \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import qalsadi.lemmatizer\n",
    "import time\n",
    "\n",
    "\n",
    "print(\"Modules Imported !! \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eca5770",
   "metadata": {},
   "source": [
    "\n",
    "# Data Preparing (Load-Clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f632977",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('data.xlsx') # data loading \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ff5a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>انشاء الله هنعمل حاجه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>اقسم باللله ان العرب اكثر الشعوب تخلفاا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>﻿هات ناس تفهم .. و المثل بحكي اسأل مجرب و لا ت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>صرماتي براس اهلك</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>حرام السخرية من الناس</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                                txt\n",
       "0        1.0                              انشاء الله هنعمل حاجه\n",
       "1        0.0            اقسم باللله ان العرب اكثر الشعوب تخلفاا\n",
       "2        0.0  ﻿هات ناس تفهم .. و المثل بحكي اسأل مجرب و لا ت...\n",
       "3        0.0                                   صرماتي براس اهلك\n",
       "4        0.0                              حرام السخرية من الناس"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # show dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e767649b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    10098\n",
       "0.0    10023\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts() #count the values of sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a0efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna() # drop and remove nan (null) value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09482fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to remove emoji's\n",
    "\n",
    "def remove_emoji(text):\n",
    "    non_arabic_char = re.compile('[^\\s\\\\u0600-\\u06FF]')\n",
    "    text_with_no_spaces = re.sub(non_arabic_char, \"\", text)\n",
    "    text_with_single_spaces = \" \".join(re.split(\"\\s+\", text_with_no_spaces))\n",
    "    \n",
    "    return text_with_single_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1140658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffهات ناس تفهم .. و المثل بحكي اسأل مجرب و لا تسأل خبير'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.txt[2] #show data before emoji's removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf571557",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"txt\"]=data[\"txt\"].map(remove_emoji) #map each row with remove_emoji's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c5d388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'هات ناس تفهم و المثل بحكي اسأل مجرب و لا تسأل خبير'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.txt[2] # show data sample after apply remove_emoji's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4350254e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>انشاء الله هنعمل حاجه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>اقسم باللله ان العرب اكثر الشعوب تخلفاا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>هات ناس تفهم و المثل بحكي اسأل مجرب و لا تسأل ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>صرماتي براس اهلك</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>حرام السخرية من الناس</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                                txt\n",
       "0        1.0                              انشاء الله هنعمل حاجه\n",
       "1        0.0            اقسم باللله ان العرب اكثر الشعوب تخلفاا\n",
       "2        0.0  هات ناس تفهم و المثل بحكي اسأل مجرب و لا تسأل ...\n",
       "3        0.0                                   صرماتي براس اهلك\n",
       "4        0.0                              حرام السخرية من الناس"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f09c1109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>انشاء الله هنعمل حاجه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>اقسم باللله ان العرب اكثر الشعوب تخلفاا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>هات ناس تفهم و المثل بحكي اسأل مجرب و لا تسأل ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>صرماتي براس اهلك</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>حرام السخرية من الناس</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>المثل يقول ان أكرمت اللئيم تمردا وهذا بالضبط ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20197</th>\n",
       "      <td>1.0</td>\n",
       "      <td>إلي سهران ريتويت بنسولف عالخاص</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>لا تهتم بشخص زياااده ،، تراك بزمن يسمون المهتم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>مكى عامل ايه انا دورت عليك كتير امبارح واتصلت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200</th>\n",
       "      <td>1.0</td>\n",
       "      <td>غردبالصوره ههههههه بكرى عندنا إجازة</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                                txt\n",
       "0            1.0                              انشاء الله هنعمل حاجه\n",
       "1            0.0            اقسم باللله ان العرب اكثر الشعوب تخلفاا\n",
       "2            0.0  هات ناس تفهم و المثل بحكي اسأل مجرب و لا تسأل ...\n",
       "3            0.0                                   صرماتي براس اهلك\n",
       "4            0.0                              حرام السخرية من الناس\n",
       "...          ...                                                ...\n",
       "20196        0.0   المثل يقول ان أكرمت اللئيم تمردا وهذا بالضبط ...\n",
       "20197        1.0                    إلي سهران ريتويت بنسولف عالخاص \n",
       "20198        0.0  لا تهتم بشخص زياااده ،، تراك بزمن يسمون المهتم...\n",
       "20199        0.0   مكى عامل ايه انا دورت عليك كتير امبارح واتصلت...\n",
       "20200        1.0                غردبالصوره ههههههه بكرى عندنا إجازة\n",
       "\n",
       "[20121 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(axis=1, how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f109062",
   "metadata": {},
   "source": [
    "# Data Preprocessing (Tokenize - Stop word remove - stemming or lemmatize) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73d41b",
   "metadata": {},
   "source": [
    "# Tokenizing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01271429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(inp):\n",
    "    return nltk.tokenize.wordpunct_tokenize(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5bdaec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "data.txt = data.txt.apply(lambda sentence: nltk.tokenize.wordpunct_tokenize(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fdbcf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[انشاء, الله, هنعمل, حاجه]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[اقسم, باللله, ان, العرب, اكثر, الشعوب, تخلفاا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[هات, ناس, تفهم, و, المثل, بحكي, اسأل, مجرب, و...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[صرماتي, براس, اهلك]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[حرام, السخرية, من, الناس]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                                txt\n",
       "0        1.0                         [انشاء, الله, هنعمل, حاجه]\n",
       "1        0.0    [اقسم, باللله, ان, العرب, اكثر, الشعوب, تخلفاا]\n",
       "2        0.0  [هات, ناس, تفهم, و, المثل, بحكي, اسأل, مجرب, و...\n",
       "3        0.0                               [صرماتي, براس, اهلك]\n",
       "4        0.0                         [حرام, السخرية, من, الناس]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7fdf65",
   "metadata": {},
   "source": [
    "# Stop word removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7961580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_removal(inp):\n",
    "    arb_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "    for i in inp:\n",
    "        if i in arb_stopwords:\n",
    "            inp.remove(i)\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b88c66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.txt=data[\"txt\"].map(stopword_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04a2ca03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[انشاء, الله, هنعمل, حاجه]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[اقسم, باللله, ان, العرب, اكثر, الشعوب, تخلفاا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[هات, ناس, تفهم, المثل, بحكي, اسأل, مجرب, لا, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[صرماتي, براس, اهلك]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[حرام, السخرية, الناس]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                                txt\n",
       "0        1.0                         [انشاء, الله, هنعمل, حاجه]\n",
       "1        0.0    [اقسم, باللله, ان, العرب, اكثر, الشعوب, تخلفاا]\n",
       "2        0.0  [هات, ناس, تفهم, المثل, بحكي, اسأل, مجرب, لا, ...\n",
       "3        0.0                               [صرماتي, براس, اهلك]\n",
       "4        0.0                             [حرام, السخرية, الناس]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2c0c11",
   "metadata": {},
   "source": [
    "# Stemming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e3171da",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=nltk.ISRIStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7c55ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stem(text):\n",
    "    out=[]\n",
    "    for i in text:\n",
    "        out.append(stemmer.stem(i))\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80d4b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------  4.122730731964111  Secounds --------\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "#data.txt.map(stem)\n",
    "\n",
    "data.txt=data.txt.map(stem)\n",
    "print(\"-------- \",(time.time() - start_time),' Secounds --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6947cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed473ad",
   "metadata": {},
   "source": [
    "# Lemmatizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341508e",
   "metadata": {},
   "source": [
    "Lemmatizing Take more time than stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d32e7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = qalsadi.lemmatizer.Lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72a30325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatize(text):\n",
    "    out=[]\n",
    "    for i in text:\n",
    "        out.append(lemmatizer.lemmatize(i))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98f01aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------  0.000141143798828125  Secounds --------\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "\n",
    "#data.txt.map(lemmatize).head\n",
    "#data.txt=data.txt.map(lemmatize)\n",
    "\n",
    "print(\"-------- \",(time.time() - start_time),' Secounds --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d94f1bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[شاء, الل, هنعمل, حجه]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[قسم, لله, ان, عرب, كثر, شعب, خلف]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[هات, ناس, فهم, مثل, بحك, سأل, جرب, لا, سأل, خبر]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[صرم, برس, اهل]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[حرم, سخر, ناس]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                                txt\n",
       "0        1.0                             [شاء, الل, هنعمل, حجه]\n",
       "1        0.0                 [قسم, لله, ان, عرب, كثر, شعب, خلف]\n",
       "2        0.0  [هات, ناس, فهم, مثل, بحك, سأل, جرب, لا, سأل, خبر]\n",
       "3        0.0                                    [صرم, برس, اهل]\n",
       "4        0.0                                    [حرم, سخر, ناس]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43da12e",
   "metadata": {},
   "source": [
    "# Words Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0eb81789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_text(txt):\n",
    "    \n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da31f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.txt=data.txt.map(join_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4fd9db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>شاء الل هنعمل حجه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>قسم لله ان عرب كثر شعب خلف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>هات ناس فهم مثل بحك سأل جرب لا سأل خبر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>صرم برس اهل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>حرم سخر ناس</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                     txt\n",
       "0        1.0                       شاء الل هنعمل حجه\n",
       "1        0.0              قسم لله ان عرب كثر شعب خلف\n",
       "2        0.0  هات ناس فهم مثل بحك سأل جرب لا سأل خبر\n",
       "3        0.0                             صرم برس اهل\n",
       "4        0.0                             حرم سخر ناس"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42a74568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class labels to  Bad and  Good values\n",
    "\n",
    "def decoder(arr):\n",
    "    out=list()\n",
    "    binary_list=list(arr)\n",
    "    for item in binary_list:\n",
    "        if item == 0:\n",
    "            out.append('bad')\n",
    "        else:\n",
    "            out.append('good')\n",
    "    return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773780fa",
   "metadata": {},
   "source": [
    "# Feature Extraction & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db5a6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extaction using Counter\n",
    "\n",
    "bag_of_words_vectorizer=CountVectorizer() \n",
    "bag_of_words_count = bag_of_words_vectorizer.fit_transform(data[\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df5300d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_count, x_test_count, y_train_count, y_test_count = train_test_split(bag_of_words_count, data['sentiment'], random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7b8a23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors  Accuracy:  0.6344663088849135  Score:  0.681668686169292\n",
      "Decision Tree  Accuracy:  0.6781951898230968  Score:  0.6802291131740075\n",
      "Random Forest  Accuracy:  0.7885112303716955  Score:  0.7880478087649403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rashed/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  Accuracy:  0.7990459153249851  Score:  0.8003160181710448\n",
      "SGD Classifier  Accuracy:  0.7934804213873982  Score:  0.7948667324777888\n",
      "Naive Bayes  Accuracy:  0.8075929238719937  Score:  0.8048387096774194\n",
      "SVM Linear  Accuracy:  0.7871198568872988  Score:  0.7887990534411358\n",
      "--------  168.0800642967224  Secounds --------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,f1_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=100),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "scored_models_count=dict()\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = model\n",
    "    nltk_model.fit(x_train_count,y_train_count)\n",
    "    pred = model.predict(x_test_count)\n",
    "    scored_models_count[name]=[model,pred]\n",
    "    score=f1_score(y_test_count, pred)\n",
    "    accuracy = accuracy_score(y_test_count,pred) \n",
    "    print(name,\" Accuracy: \", accuracy,\" Score: \",score )\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "print(\"-------- \",(time.time() - start_time),' Secounds --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02cfbd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary values : [1.]\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "type of test : <class 'scipy.sparse.csr.csr_matrix'>\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "matrix :    (0, 1722)\t1\n",
      "  (0, 2837)\t1\n",
      "  (0, 2982)\t1\n",
      "  (0, 3267)\t1\n",
      "  (0, 3923)\t1\n",
      "  (0, 4683)\t1\n",
      "  (0, 7348)\t1\n",
      "  (0, 8049)\t1\n",
      "  (0, 9234)\t1\n",
      "  (0, 10108)\t2\n",
      "  (0, 10979)\t1\n",
      "  (0, 11452)\t1\n",
      "  (0, 11645)\t1\n",
      "  (0, 13787)\t1\n",
      "  (0, 16400)\t1\n",
      "  (0, 16706)\t1\n",
      "  (0, 19032)\t1\n",
      "  (0, 21864)\t1\n",
      "  (0, 22978)\t1\n",
      "  (0, 24510)\t1\n",
      "  (0, 25743)\t1\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "test matrix shape : (5031, 26364)\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      " actual labels : ['good']\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "bad Tweets =  0 good tweets =  1\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test a specific model\n",
    "test=scored_models_count['Random Forest'][0].predict(x_test_count[1])\n",
    "print(\"binary values :\",test[:10])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "result=decoder(test)\n",
    "print('type of test :',type(x_test_count))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('matrix : ',x_test_count[1])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('test matrix shape :',x_test_count.shape)\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print(\" actual labels :\",result[:10])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('bad Tweets = ',result.count('bad'),'good tweets = ', result.count('good'))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "918427df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.82      0.81      2521\n",
      "         1.0       0.81      0.80      0.80      2510\n",
      "\n",
      "    accuracy                           0.81      5031\n",
      "   macro avg       0.81      0.81      0.81      5031\n",
      "weighted avg       0.81      0.81      0.81      5031\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>bad</th>\n",
       "      <td>2067</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>514</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted      \n",
       "                  bad  good\n",
       "actual bad       2067   454\n",
       "       good       514  1996"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a confusion matrix and a classification report\n",
    "print(classification_report(y_test_count, scored_models_count['Naive Bayes'][1]))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test_count, scored_models_count['Naive Bayes'][1]),\n",
    "    index = [['actual', 'actual'], ['bad', 'good']],\n",
    "    columns = [['predicted', 'predicted'], ['bad', 'good']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f04238",
   "metadata": {},
   "source": [
    "# ____________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b59ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction using binary victor\n",
    "\n",
    "bag_of_words_vectorizer_binary=CountVectorizer(binary=True) \n",
    "bag_of_words_binary = bag_of_words_vectorizer_binary.fit_transform(data[\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7846aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bin, x_test_bin, y_train_bin, y_test_bin = train_test_split(bag_of_words_binary, data['sentiment'], random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1485fa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors  Accuracy:  0.6535480023852117  Score:  0.7014899811611577\n",
      "Decision Tree  Accuracy:  0.693500298151461  Score:  0.6948951325682627\n",
      "Random Forest  Accuracy:  0.774597495527728  Score:  0.7774725274725274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rashed/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  Accuracy:  0.7962631683561916  Score:  0.7969090548840895\n",
      "SGD Classifier  Accuracy:  0.7869210892466706  Score:  0.7908700741318768\n",
      "Naive Bayes  Accuracy:  0.808189226793878  Score:  0.8068068068068067\n",
      "SVM Linear  Accuracy:  0.7827469687934804  Score:  0.7865651239992189\n",
      "--------  159.35423183441162  Secounds --------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,f1_score\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=100),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "scored_models_bin=dict()\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = model\n",
    "    nltk_model.fit(x_train_bin,y_train_bin)\n",
    "    pred = model.predict(x_test_bin)\n",
    "    scored_models_bin[name]=[model,pred]\n",
    "    score=f1_score(y_test_bin, pred)\n",
    "    accuracy = accuracy_score(y_test_bin,pred) \n",
    "    print(name,\" Accuracy: \", accuracy,\" Score: \",score )\n",
    "    \n",
    "print(\"-------- \",(time.time() - start_time),' Secounds --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "613e484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary values : [1.]\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "type of test : <class 'scipy.sparse.csr.csr_matrix'>\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "matrix :    (0, 1722)\t1\n",
      "  (0, 2837)\t1\n",
      "  (0, 2982)\t1\n",
      "  (0, 3267)\t1\n",
      "  (0, 3923)\t1\n",
      "  (0, 4683)\t1\n",
      "  (0, 7348)\t1\n",
      "  (0, 8049)\t1\n",
      "  (0, 9234)\t1\n",
      "  (0, 10108)\t1\n",
      "  (0, 10979)\t1\n",
      "  (0, 11452)\t1\n",
      "  (0, 11645)\t1\n",
      "  (0, 13787)\t1\n",
      "  (0, 16400)\t1\n",
      "  (0, 16706)\t1\n",
      "  (0, 19032)\t1\n",
      "  (0, 21864)\t1\n",
      "  (0, 22978)\t1\n",
      "  (0, 24510)\t1\n",
      "  (0, 25743)\t1\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "test matrix shape : (5031, 26364)\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      " actual labels : ['good']\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "bad Tweets =  0 good tweets =  1\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test a specific model\n",
    "test=scored_models_bin['Random Forest'][0].predict(x_test_bin[1])\n",
    "print(\"binary values :\",test[:])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "result=decoder(test)\n",
    "print('type of test :',type(x_test_bin))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('matrix : ',x_test_bin[1])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('test matrix shape :',x_test_bin.shape)\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print(\" actual labels :\",result[:10])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('bad Tweets = ',result.count('bad'),'good tweets = ', result.count('good'))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "190b305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.81      0.81      2521\n",
      "         1.0       0.81      0.80      0.81      2510\n",
      "\n",
      "    accuracy                           0.81      5031\n",
      "   macro avg       0.81      0.81      0.81      5031\n",
      "weighted avg       0.81      0.81      0.81      5031\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>bad</th>\n",
       "      <td>2051</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>495</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted      \n",
       "                  bad  good\n",
       "actual bad       2051   470\n",
       "       good       495  2015"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a confusion matrix and a classification report\n",
    "print(classification_report(y_test_bin, scored_models_bin['Naive Bayes'][1]))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test_bin, scored_models_bin['Naive Bayes'][1]),\n",
    "    index = [['actual', 'actual'], ['bad', 'good']],\n",
    "    columns = [['predicted', 'predicted'], ['bad', 'good']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ccb2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction using TF-IDF\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "bag_of_words_tfidf=vectorizer.fit_transform(data[\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eff887fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf, x_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(bag_of_words_tfidf, data['sentiment'], random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65aa75a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors  Accuracy:  0.516994633273703  Score:  0.5246478873239437\n",
      "Decision Tree  Accuracy:  0.6813754720731465  Score:  0.6784353059177533\n",
      "Random Forest  Accuracy:  0.7948717948717948  Score:  0.7905844155844155\n",
      "Logistic Regression  Accuracy:  0.8073941562313656  Score:  0.8047551883941164\n",
      "SGD Classifier  Accuracy:  0.810176903200159  Score:  0.8066410204494836\n",
      "Naive Bayes  Accuracy:  0.8207115881534486  Score:  0.8218799368088467\n",
      "SVM Linear  Accuracy:  0.804611409262572  Score:  0.8027292795504716\n",
      "--------  102.88230919837952  Secounds --------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,f1_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=100),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "scored_models_tfidf=dict()\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = model\n",
    "    nltk_model.fit(x_train_tfidf,y_train_tfidf)\n",
    "    pred = model.predict(x_test_tfidf)\n",
    "    scored_models_tfidf[name]=[model,pred]\n",
    "    score=f1_score(y_test_tfidf, pred)\n",
    "    accuracy = accuracy_score(y_test_tfidf,pred) \n",
    "    print(name,\" Accuracy: \", accuracy,\" Score: \",score )\n",
    "    \n",
    "    \n",
    "print(\"-------- \",(time.time() - start_time),' Secounds --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2b1c56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary values : [1.]\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "type of test : <class 'scipy.sparse.csr.csr_matrix'>\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "matrix :    (0, 1722)\t0.20717938458819832\n",
      "  (0, 2837)\t0.29545162715649076\n",
      "  (0, 2982)\t0.1995371340950331\n",
      "  (0, 3267)\t0.1714275913345165\n",
      "  (0, 3923)\t0.16563322745814968\n",
      "  (0, 4683)\t0.22921770841588138\n",
      "  (0, 7348)\t0.1435546184138506\n",
      "  (0, 8049)\t0.1817641666610479\n",
      "  (0, 9234)\t0.20654670334082717\n",
      "  (0, 10108)\t0.20227709592114218\n",
      "  (0, 10979)\t0.12689189405816081\n",
      "  (0, 11452)\t0.1294064019785209\n",
      "  (0, 11645)\t0.13294388185263173\n",
      "  (0, 13787)\t0.13052605908760084\n",
      "  (0, 16400)\t0.11623471159652991\n",
      "  (0, 16706)\t0.31597375486081364\n",
      "  (0, 19032)\t0.3244629770211133\n",
      "  (0, 21864)\t0.28112241497938967\n",
      "  (0, 22978)\t0.25208811485484334\n",
      "  (0, 24510)\t0.26076130724574786\n",
      "  (0, 25743)\t0.2943198782626292\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "test matrix shape : (5031, 26364)\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      " actual labels : ['good']\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "bad Tweets =  0 good tweets =  1\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test a specific model\n",
    "test=scored_models_tfidf['Random Forest'][0].predict(x_test_tfidf[1])\n",
    "print(\"binary values :\",test[:10])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "result=decoder(test)\n",
    "print('type of test :',type(x_test_tfidf))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('matrix : ',x_test_tfidf[1])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('test matrix shape :',x_test_tfidf.shape)\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print(\" actual labels :\",result[:10])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('bad Tweets = ',result.count('bad'),'good tweets = ', result.count('good'))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b9dd5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.81      0.82      2521\n",
      "         1.0       0.81      0.83      0.82      2510\n",
      "\n",
      "    accuracy                           0.82      5031\n",
      "   macro avg       0.82      0.82      0.82      5031\n",
      "weighted avg       0.82      0.82      0.82      5031\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>bad</th>\n",
       "      <td>2048</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>429</td>\n",
       "      <td>2081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted      \n",
       "                  bad  good\n",
       "actual bad       2048   473\n",
       "       good       429  2081"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a confusion matrix and a classification report\n",
    "print(classification_report(y_test_tfidf, scored_models_tfidf['Naive Bayes'][1]))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test_tfidf, scored_models_tfidf['Naive Bayes'][1]),\n",
    "    index = [['actual', 'actual'], ['bad', 'good']],\n",
    "    columns = [['predicted', 'predicted'], ['bad', 'good']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ba6ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "#import pickle\n",
    "\n",
    "#filename = 'Naive Bayes model.sav'\n",
    "#pickle.dump(scored_models_tfidf['Naive Bayes'][0], open(filename, 'wb'))\n",
    " \n",
    "#load model from disk \n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.score(x_test_tfidf, y_test_tfidf)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47ba5cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K Nearest Neighbors': [KNeighborsClassifier(),\n",
       "  array([1., 1., 1., ..., 0., 0., 0.])],\n",
       " 'Decision Tree': [DecisionTreeClassifier(),\n",
       "  array([1., 0., 1., ..., 0., 1., 0.])],\n",
       " 'Random Forest': [RandomForestClassifier(),\n",
       "  array([1., 1., 1., ..., 0., 1., 0.])],\n",
       " 'Logistic Regression': [LogisticRegression(),\n",
       "  array([1., 1., 0., ..., 1., 1., 0.])],\n",
       " 'SGD Classifier': [SGDClassifier(max_iter=100),\n",
       "  array([1., 1., 1., ..., 0., 1., 0.])],\n",
       " 'Naive Bayes': [MultinomialNB(), array([1., 1., 0., ..., 0., 1., 0.])],\n",
       " 'SVM Linear': [SVC(kernel='linear'), array([1., 1., 0., ..., 1., 1., 0.])]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_models_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c34e049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K Nearest Neighbors': [KNeighborsClassifier(),\n",
       "  array([1., 1., 1., ..., 1., 1., 1.])],\n",
       " 'Decision Tree': [DecisionTreeClassifier(),\n",
       "  array([1., 1., 0., ..., 1., 1., 0.])],\n",
       " 'Random Forest': [RandomForestClassifier(),\n",
       "  array([1., 1., 0., ..., 0., 0., 0.])],\n",
       " 'Logistic Regression': [LogisticRegression(),\n",
       "  array([1., 1., 1., ..., 0., 1., 0.])],\n",
       " 'SGD Classifier': [SGDClassifier(max_iter=100),\n",
       "  array([1., 1., 0., ..., 1., 1., 0.])],\n",
       " 'Naive Bayes': [MultinomialNB(), array([1., 1., 0., ..., 0., 1., 0.])],\n",
       " 'SVM Linear': [SVC(kernel='linear'), array([1., 1., 1., ..., 1., 1., 0.])]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_models_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f0dab89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K Nearest Neighbors': [KNeighborsClassifier(),\n",
       "  array([0., 1., 0., ..., 1., 1., 1.])],\n",
       " 'Decision Tree': [DecisionTreeClassifier(),\n",
       "  array([1., 0., 1., ..., 0., 1., 0.])],\n",
       " 'Random Forest': [RandomForestClassifier(),\n",
       "  array([1., 1., 1., ..., 0., 1., 0.])],\n",
       " 'Logistic Regression': [LogisticRegression(),\n",
       "  array([1., 1., 1., ..., 0., 1., 0.])],\n",
       " 'SGD Classifier': [SGDClassifier(max_iter=100),\n",
       "  array([1., 1., 1., ..., 0., 1., 0.])],\n",
       " 'Naive Bayes': [MultinomialNB(), array([1., 1., 0., ..., 0., 1., 0.])],\n",
       " 'SVM Linear': [SVC(kernel='linear'), array([1., 1., 1., ..., 0., 1., 0.])]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_models_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402505c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
