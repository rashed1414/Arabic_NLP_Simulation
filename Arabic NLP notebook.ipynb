{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "705a0501",
   "metadata": {},
   "source": [
    "# Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df4a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import qalsadi.lemmatizer\n",
    "import time\n",
    "\n",
    "\n",
    "print(\"Modules Imported !! \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eca5770",
   "metadata": {},
   "source": [
    "\n",
    "# Data Preparing (Load-Clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f632977",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('data.xlsx') # data loading \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head() # show dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'].value_counts() #count the values of sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a0efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna() # drop and remove nan (null) value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09482fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to remove emoji's\n",
    "\n",
    "def remove_emoji(text):\n",
    "    non_arabic_char = re.compile('[^\\s\\\\u0600-\\u06FF]')\n",
    "    text_with_no_spaces = re.sub(non_arabic_char, \"\", text)\n",
    "    text_with_single_spaces = \" \".join(re.split(\"\\s+\", text_with_no_spaces))\n",
    "    \n",
    "    return text_with_single_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1140658",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.txt[2] #show data before emoji's removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf571557",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"txt\"]=data[\"txt\"].map(remove_emoji) #map each row with remove_emoji's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.txt[2] # show data sample after apply remove_emoji's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4350254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=1, how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f109062",
   "metadata": {},
   "source": [
    "# Data Preprocessing (Tokenize - Stop word remove - stemming or lemmatize) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73d41b",
   "metadata": {},
   "source": [
    "# Tokenizing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01271429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(inp):\n",
    "    return nltk.tokenize.wordpunct_tokenize(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bdaec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "data.txt = data.txt.apply(lambda sentence: nltk.tokenize.wordpunct_tokenize(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdbcf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7fdf65",
   "metadata": {},
   "source": [
    "# Stop word removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7961580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_removal(inp):\n",
    "    arb_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "    for i in inp:\n",
    "        if i in arb_stopwords:\n",
    "            inp.remove(i)\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.txt=data[\"txt\"].map(stopword_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2ca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2c0c11",
   "metadata": {},
   "source": [
    "# Stemming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3171da",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=nltk.ISRIStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c55ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stem(text):\n",
    "    out=[]\n",
    "    for i in text:\n",
    "        out.append(stemmer.stem(i))\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d4b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "#data.txt.map(stem)\n",
    "\n",
    "data.txt=data.txt.map(stem)\n",
    "print(\"-------- \",(time.time() - start_time),' Secounds --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed473ad",
   "metadata": {},
   "source": [
    "# Lemmatizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341508e",
   "metadata": {},
   "source": [
    "Lemmatizing Take more time than stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32e7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = qalsadi.lemmatizer.Lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a30325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatize(text):\n",
    "    out=[]\n",
    "    for i in text:\n",
    "        out.append(lemmatizer.lemmatize(i))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f01aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "\n",
    "#data.txt.map(lemmatize).head\n",
    "#data.txt=data.txt.map(lemmatize)\n",
    "\n",
    "print(\"-------- \",(time.time() - start_time),' Secounds --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f1bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43da12e",
   "metadata": {},
   "source": [
    "# Words Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb81789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_text(txt):\n",
    "    \n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da31f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.txt=data.txt.map(join_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd9db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a74568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class labels to  Bad and  Good values\n",
    "\n",
    "def decoder(arr):\n",
    "    out=list()\n",
    "    binary_list=list(arr)\n",
    "    for item in binary_list:\n",
    "        if item == 0:\n",
    "            out.append('bad')\n",
    "        else:\n",
    "            out.append('good')\n",
    "    return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773780fa",
   "metadata": {},
   "source": [
    "# Feature Extraction & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extaction using Counter\n",
    "\n",
    "bag_of_words_vectorizer=CountVectorizer() \n",
    "bag_of_words_count = bag_of_words_vectorizer.fit_transform(data[\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5300d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_count, x_test_count, y_train_count, y_test_count = train_test_split(bag_of_words_count, data['sentiment'], random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,f1_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=100),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "scored_models_count=dict()\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = model\n",
    "    nltk_model.fit(x_train_count,y_train_count)\n",
    "    pred = model.predict(x_test_count)\n",
    "    scored_models_count[name]=[model,pred]\n",
    "    score=f1_score(y_test_count, pred)\n",
    "    accuracy = accuracy_score(y_test_count,pred) \n",
    "    print(name,\" Accuracy: \", accuracy,\" Score: \",score )\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "print(\"-------- \",(time.time() - start_time),' Secounds --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfbd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test a specific model\n",
    "test=scored_models_count['Random Forest'][0].predict(x_test_count[1])\n",
    "print(\"binary values :\",test[:10])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "result=decoder(test)\n",
    "print('type of test :',type(x_test_count))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('matrix : ',x_test_count[1])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('test matrix shape :',x_test_count.shape)\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print(\" actual labels :\",result[:10])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('bad Tweets = ',result.count('bad'),'good tweets = ', result.count('good'))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918427df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a confusion matrix and a classification report\n",
    "print(classification_report(y_test_count, scored_models_count['Naive Bayes'][1]))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test_count, scored_models_count['Naive Bayes'][1]),\n",
    "    index = [['actual', 'actual'], ['bad', 'good']],\n",
    "    columns = [['predicted', 'predicted'], ['bad', 'good']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f04238",
   "metadata": {},
   "source": [
    "# ____________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction using binary victor\n",
    "\n",
    "bag_of_words_vectorizer_binary=CountVectorizer(binary=True) \n",
    "bag_of_words_binary = bag_of_words_vectorizer_binary.fit_transform(data[\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bin, x_test_bin, y_train_bin, y_test_bin = train_test_split(bag_of_words_binary, data['sentiment'], random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,f1_score\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=100),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "scored_models_bin=dict()\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = model\n",
    "    nltk_model.fit(x_train_bin,y_train_bin)\n",
    "    pred = model.predict(x_test_bin)\n",
    "    scored_models_bin[name]=[model,pred]\n",
    "    score=f1_score(y_test_bin, pred)\n",
    "    accuracy = accuracy_score(y_test_bin,pred) \n",
    "    print(name,\" Accuracy: \", accuracy,\" Score: \",score )\n",
    "    \n",
    "print(\"-------- \",(time.time() - start_time),' Secounds --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test a specific model\n",
    "test=scored_models_bin['Random Forest'][0].predict(x_test_bin[1])\n",
    "print(\"binary values :\",test[:])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "result=decoder(test)\n",
    "print('type of test :',type(x_test_bin))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('matrix : ',x_test_bin[1])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('test matrix shape :',x_test_bin.shape)\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print(\" actual labels :\",result[:10])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('bad Tweets = ',result.count('bad'),'good tweets = ', result.count('good'))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a confusion matrix and a classification report\n",
    "print(classification_report(y_test_bin, scored_models_bin['Naive Bayes'][1]))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test_bin, scored_models_bin['Naive Bayes'][1]),\n",
    "    index = [['actual', 'actual'], ['bad', 'good']],\n",
    "    columns = [['predicted', 'predicted'], ['bad', 'good']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction using TF-IDF\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "bag_of_words_tfidf=vectorizer.fit_transform(data[\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff887fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf, x_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(bag_of_words_tfidf, data['sentiment'], random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,f1_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(solver='lbfgs', max_iter=100),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "scored_models_tfidf=dict()\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = model\n",
    "    nltk_model.fit(x_train_tfidf,y_train_tfidf)\n",
    "    pred = model.predict(x_test_tfidf)\n",
    "    scored_models_tfidf[name]=[model,pred]\n",
    "    score=f1_score(y_test_tfidf, pred)\n",
    "    accuracy = accuracy_score(y_test_tfidf,pred) \n",
    "    print(name,\" Accuracy: \", accuracy,\" Score: \",score )\n",
    "    \n",
    "    \n",
    "print(\"-------- \",(time.time() - start_time),' Secounds --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test a specific model\n",
    "test=scored_models_tfidf['Random Forest'][0].predict(x_test_tfidf[1])\n",
    "print(\"binary values :\",test[:10])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "result=decoder(test)\n",
    "print('type of test :',type(x_test_tfidf))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('matrix : ',x_test_tfidf[1])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('test matrix shape :',x_test_tfidf.shape)\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print(\" actual labels :\",result[:10])\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')\n",
    "print('bad Tweets = ',result.count('bad'),'good tweets = ', result.count('good'))\n",
    "print('''\n",
    "-------------------------------------\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9dd5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a confusion matrix and a classification report\n",
    "print(classification_report(y_test_tfidf, scored_models_tfidf['Naive Bayes'][1]))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test_tfidf, scored_models_tfidf['Naive Bayes'][1]),\n",
    "    index = [['actual', 'actual'], ['bad', 'good']],\n",
    "    columns = [['predicted', 'predicted'], ['bad', 'good']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "#import pickle\n",
    "\n",
    "#filename = 'Naive Bayes model.sav'\n",
    "#pickle.dump(scored_models_tfidf['Naive Bayes'][0], open(filename, 'wb'))\n",
    " \n",
    "#load model from disk \n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.score(x_test_tfidf, y_test_tfidf)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_models_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_models_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0dab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_models_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402505c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
